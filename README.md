<div align="center">



### My _geeked_ homelab k8s cluster <img src="https://fonts.gstatic.com/s/e/notoemoji/latest/1f680/512.gif" alt="ðŸš€" width="16" height="16">

_... automated via [Flux](https://github.com/fluxcd/flux2), [Renovate](https://github.com/renovatebot/renovate)  <img src="https://fonts.gstatic.com/s/e/notoemoji/latest/1f916/512.gif" alt="ðŸ¤–" width="16" height="16">

</div>

<div align="center">

[![Discord](https://img.shields.io/discord/673534664354430999?style=for-the-badge&label&logo=discord&logoColor=white&color=blue)](https://discord.gg/home-operations)&nbsp;&nbsp;
[![Talos](https://img.shields.io/endpoint?url=https%3A%2F%2Fkromgo.dartus.fr%2Ftalos_version&style=for-the-badge&logo=talos&logoColor=white&color=blue&label=%20)](https://talos.dev)&nbsp;&nbsp;
[![Kubernetes](https://img.shields.io/endpoint?url=https%3A%2F%2Fkromgo.dartus.fr%2Fkubernetes_version&style=for-the-badge&logo=kubernetes&logoColor=white&color=blue&label=%20)](https://kubernetes.io)&nbsp;&nbsp;
[![Flux](https://img.shields.io/endpoint?url=https%3A%2F%2Fkromgo.dartus.fr%2Fflux_version&style=for-the-badge&logo=flux&logoColor=white&color=blue&label=%20)](https://fluxcd.io)&nbsp;&nbsp;
[![Renovate](https://img.shields.io/github/actions/workflow/status/rdartus/home-ops/renovate.yaml?branch=main&label=&logo=renovatebot&style=for-the-badge&color=blue)](https://github.com/rdartus/home-ops/actions/workflows/renovate.yaml)

</div>

<div align="center">

[![Alertmanager](https://img.shields.io/endpoint?url=https%3A%2F%2Fhealthchecks.io%2Fb%2F2%2Fd6a71d48-9e97-4ba0-b7a0-ed0677d78304.shields&style=for-the-badge&logo=prometheus&logoColor=white&label=Alertmanager)](https://status.k13.dev)

</div>

<div align="center">

[![Age-Days](https://img.shields.io/endpoint?url=https%3A%2F%2Fkromgo.dartus.fr%2Fcluster_age_days&style=flat-square&label=Age)](https://github.com/kashalls/kromgo)&nbsp;&nbsp;
[![Uptime-Days](https://img.shields.io/endpoint?url=https%3A%2F%2Fkromgo.dartus.fr%2Fcluster_uptime_days&style=flat-square&label=Uptime)](https://github.com/kashalls/kromgo)&nbsp;&nbsp;
[![Node-Count](https://img.shields.io/endpoint?url=https%3A%2F%2Fkromgo.dartus.fr%2Fcluster_node_count&style=flat-square&label=Nodes)](https://github.com/kashalls/kromgo)&nbsp;&nbsp;
[![Pod-Count](https://img.shields.io/endpoint?url=https%3A%2F%2Fkromgo.dartus.fr%2Fcluster_pod_count&style=flat-square&label=Pods)](https://github.com/kashalls/kromgo)&nbsp;&nbsp;
[![CPU-Usage](https://img.shields.io/endpoint?url=https%3A%2F%2Fkromgo.dartus.fr%2Fcluster_cpu_usage&style=flat-square&label=CPU)](https://github.com/kashalls/kromgo)&nbsp;&nbsp;
[![Memory-Usage](https://img.shields.io/endpoint?url=https%3A%2F%2Fkromgo.dartus.fr%2Fcluster_memory_usage&style=flat-square&label=Memory)](https://github.com/kashalls/kromgo)&nbsp;&nbsp;
[![Power-Usage](https://img.shields.io/endpoint?url=https%3A%2F%2Fkromgo.dartus.fr%2Fcluster_power_usage&style=flat-square&label=Power)](https://github.com/kashalls/kromgo)&nbsp;&nbsp;
[![Alerts](https://img.shields.io/endpoint?url=https%3A%2F%2Fkromgo.dartus.fr%2Fcluster_alert_count&style=flat-square&label=Alerts)](https://github.com/kashalls/kromgo)

</div>

---

## <img src="https://fonts.gstatic.com/s/e/notoemoji/latest/1f4a1/512.gif" alt="ðŸ’¡" width="20" height="20"> Overview

This is a repository for my home infrastructure and Kubernetes cluster. I try to adhere to Infrastructure as Code (IaC) and GitOps practices using tools like [Kubernetes](https://github.com/kubernetes/kubernetes), [Flux](https://github.com/fluxcd/flux2), [Renovate](https://github.com/renovatebot/renovate), and [GitHub Actions](https://github.com/features/actions).

---

## <img src="https://fonts.gstatic.com/s/e/notoemoji/latest/1faa9/512.gif" alt="ðŸª©" width="20" height="20"> Kubernetes

This hobo cluster operates on [Talos Linux](https://github.com/siderolabs/talos), an immutable and ephemeral Linux distribution tailored for [Kubernetes](https://github.com/kubernetes/kubernetes), and is deployed on bare-metal [RPI](https://store.minisforum.com/products/minisforum-ms-a2) & [NUC](https://store.minisforum.com/products/minisforum-ms-a2) workstations. [Longhorn](https://github.com/rook/rook) supplies my workloads with persistent block, object, and file storage, while a separate server handles media file storage. The cluster is designed to enable a full teardown without any data loss but some downtime.

There is a template at [onedr0p/cluster-template](https://github.com/onedr0p/cluster-template) if you want to follow along with some of the practices I use here.

### Core Components

- [cert-manager](https://github.com/cert-manager/cert-manager): Creates SSL certificates for services in my cluster.
- [longhron](https://longhorn.io/): Distributed block storage for peristent storage.
- [flannel](https://flannel) : internal networking for my workloads.
- [vault](https://vault): Creates SSL certificates for services in my cluster.
- [wireguard](https://wireguard): VPN for remote access & local ip address while roaming.
- [Postgres](https://wireguard): CNPG Operator for eazy PG Management.
- [MetalLB](https://wireguard): LB to expose only 1 IP to router.
- [Authentik](https://wireguard): IDM, SSO for securing the apps.
- [Hajimari](https://wireguard): Sleek but unmaintained home page.

### GitOps

[Flux](https://github.com/fluxcd/flux2) watches my [kubernetes](./kubernetes) folder (see Directories below) and makes the changes to my clusters based on the state of my Git repository.

The way Flux works for me here is it will recursively search the [kubernetes/apps](./kubernetes/apps) folder until it finds the most top level `kustomization.yaml` per directory and then apply all the resources listed in it. That aforementioned `kustomization.yaml` will generally only have a namespace resource and one or many Flux kustomizations (`ks.yaml`). Under the control of those Flux kustomizations there will be a `HelmRelease` or other resources related to the application which will be applied.

[Renovate](https://github.com/renovatebot/renovate) monitors my **entire** repository for dependency updates, automatically creating a PR when updates are found. When some PRs are merged Flux applies the changes to my cluster.

### Directories

This Git repository contains the following directories under [kubernetes](./kubernetes).

```sh
ðŸ“ kubernetes      # Kubernetes cluster defined as code
â”œâ”€ðŸ“ apps          # Apps deployed into my cluster grouped by namespace (see below)
â”œâ”€ðŸ“ components    # Re-usable kustomize components
â””â”€ðŸ“ flux          # Flux system configuration
```

### Cluster layout

This is a high-level look how Flux deploys my applications with dependencies. Below there are 3 Flux kustomizations `postgres`, `postgres-cluster`, and `atuin`. `postgres` is the first app that needs to be running and healthy before `postgres-cluster` and once `postgres-cluster` is healthy `atuin` will be deployed.

```mermaid
graph TD;
  id1>Kustomization: flux-system] -->|Creates| id2>Kustomization: cluster-apps];
  id2>Kustomization: cluster-apps] -->|Creates| id3>Kustomization: postgres];
  id2>Kustomization: cluster-apps] -->|Creates| id5>Kustomization: postgres-cluster]
  id2>Kustomization: cluster-apps] -->|Creates| id8>Kustomization: atuin]
  id3>Kustomization: postgres] -->|Creates| id4(HelmRelease: postgres);
  id5>Kustomization: postgres-cluster] -->|Depends on| id3>Kustomization: postgres];
  id5>Kustomization: postgres-cluster] -->|Creates| id10(Cluster: postgres);
  id8>Kustomization: atuin] -->|Creates| id9(HelmRelease: atuin);
  id8>Kustomization: atuin] -->|Depends on| id5>Kustomization: postgres-cluster];
```

### Networking

<details>
  <summary>Click to see a high-level network diagram</summary>

  <img src="https://github.com/user-attachments/assets/c6bb2848-d900-4796-975b-4e80dcba4850" align="center" width="600px" alt="network"/>
</details>

---

## <img src="https://fonts.gstatic.com/s/e/notoemoji/latest/1f30e/512.gif" alt="ðŸŒŽ" width="20" height="20"> DNS

In my cluster there are two instances of [ExternalDNS](https://github.com/kubernetes-sigs/external-dns) running. One for syncing private DNS records to my `UDM Pro Max` using [ExternalDNS webhook provider for UniFi](https://github.com/kashalls/external-dns-unifi-webhook), while another instance syncs public DNS to `Cloudflare`. This setup is managed by creating routes with two specific gatways: `internal` for private DNS and `external` for public DNS. The `external-dns` instances then syncs the DNS records to their respective platforms accordingly.

---

## <img src="https://fonts.gstatic.com/s/e/notoemoji/latest/2699_fe0f/512.gif" alt="âš™" width="20" height="20"> Hardware


| Device                        | Count | OS Disk Size   | Data Disk Size             | Ram   | Operating System | Purpose                 |
|-------------------------------|-------|---------------|-----------------------------|-------|------------------|-------------------------|
| Intel NUC                     | 1     | 160GB M.2     | -                           | 16GB  | Talos            | Kubernetes              |
| Raspberry Pi 5                | 1     | 64GB (SD)     | -                           | 8GB   | Talos            | Kubernetes              |
| Raspberry Pi 4                | 1     | 64GB (SD)     | -                           | 8GB   | PiKVM            | NAS                     |
| Raspberry Pi ZeroW            | 1     | 16GB (SD)     | -                           | 0,5GB | Raspberry Pi OS  | DNS Server              |

---


## <img src="https://fonts.gstatic.com/s/e/notoemoji/latest/1f31f/512.gif" alt="ðŸŒŸ" width="20" height="20"> Stargazers

<div align="center">

<a href="https://star-history.com/#rdartus/home-ops&Date">
  <picture>
    <source media="(prefers-color-scheme: dark)" srcset="https://api.star-history.com/svg?repos=rdartus/home-ops&type=Date&theme=dark" />
    <source media="(prefers-color-scheme: light)" srcset="https://api.star-history.com/svg?repos=rdartus/home-ops&type=Date" />
    <img alt="Star History Chart" src="https://api.star-history.com/svg?repos=rdartus/home-ops&type=Date" />
  </picture>
</a>

</div>

---

## <img src="https://fonts.gstatic.com/s/e/notoemoji/latest/1f64f/512.gif" alt="ðŸ™" width="20" height="20"> Gratitude and Thanks

Many thanks to all the fantastic people who donate their time to the [Home Operations](https://discord.gg/home-operations) Discord community. Be sure to check out [kubesearch.dev](https://kubesearch.dev) for ideas on how to deploy applications or get ideas on what you may deploy.

---

## <img src="https://fonts.gstatic.com/s/e/notoemoji/latest/1f6a7/512.gif" alt="ðŸš§" width="20" height="20"> Changelog

See the latest [release](https://github.com/rdartus/home-ops/releases/latest) notes.

---

## <img src="https://fonts.gstatic.com/s/e/notoemoji/latest/2696_fe0f/512.gif" alt="âš–" width="20" height="20"> License

See [LICENSE](./LICENSE).

---
## <img src="https://fonts.gstatic.com/s/e/notoemoji/latest/1f308/512.gif" alt="ðŸŒˆ" width="20" height="20"> Usefull notes & cmd
WSL Conf
``` zsh
cd ~/code/jeanpi/ && sudo docker compose down && cp ~/config/radarr/radarr.db ~/tmp/radarr.db && cp ~/config/sonarr/sonarr.db ~/tmp/sonarr.db && cp ~/config/prowlarr/prowlarr.db ~/tmp/prowlarr.db && cd ~/code/jeanpi/ && sudo docker compose up -d

scp -P 22022 jeank@192.168.1.32:/home/jeank/.kube/config /home/jeank/.kube/config
scp -P 22022 jeank@192.168.1.16:/home/jeank/tmp/prowlarr.db /home/jeank/k3s-argo/db/prowlarr.db
scp -P 22022 jeank@192.168.1.16:/home/jeank/tmp/radarr.db /home/jeank/k3s-argo/db/radarr.db
scp -P 22022 jeank@192.168.1.16:/home/jeank/tmp/sonarr.db /home/jeank/k3s-argo/db/sonarr.db
scp /home/jeank/k3s-argo/db/prowlarr.db jeank@192.168.1.32:/home/jeank/k3s-argo/db/prowlarr.db
scp /home/jeank/k3s-argo/db/radarr.db jeank@192.168.1.32:/home/jeank/k3s-argo/db/radarr.db
scp /home/jeank/k3s-argo/db/sonarr.db jeank@192.168.1.32:/home/jeank/k3s-argo/db/sonarr.db
sed -i 's/127.0.0.1/192.168.1.32/g' ~/.kube/config
```

Deploy JeanKluter & K3S : 
``` zsh
kubectl apply -k ~/k3s-argo/localApps/kusto-argo/
kubectl apply -k ~/k3s-argo/localApps
sudo k3s ctl images import k3s-argo/pgloader.tar
```
Vault Conf :
```zsh
mkdir ~/cred
sudo chown jeank:1000 cred
kubectl exec -it vault-0 -- /bin/sh vault auth enable kubernetes
kubectl exec -it vault-0 -- /bin/sh vault operator init -key-shares=3 -key-threshold=2
kubectl exec -it vault-0 -- /bin/sh vault operator
kubectl exec -it $(kubectl get pod -l app.kubernetes.io/name=traefik -n traefik -o jsonpath='{.items[0].metadata.name}') -n traefik -- /bin/sh

```

Get logs
```zsh
kubectl logs svc/argocd-server -n argocd  > argo.log && kubectl logs svc/argocd-repo-server -n argocd  > argorepo.log && kubectl logs svc/webhook-service -n metallb > metallb.log && kubectl logs pod/speaker-stlm6 -n metallb > speaker.log
```

Delete :
```zsh
kubectl delete pod -l app.kubernetes.io/component=speaker -n metallb
```
